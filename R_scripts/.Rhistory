dados_normalizados <- as.data.frame(scale(dados, center = mins, scale = maxs - mins))
dados_normalizados <- as.data.frame(scale(df[ ,numeric_columns], center = mins, scale = maxs - mins))
head(dados_normalizados)
summary(dados_normalizados)
normalized_df <- as.data.frame(scale(df[ ,numeric_columns], center = mins, scale = maxs - mins))
head(normalized_df)
summary(normalized_df)
# Correlation between numeric variable
data_cor <- cor(df[ ,numeric_columns])
data_cor
# Correlation plot
corrplot(data_cor, method = 'color')
# G3 histogram
ggplot(df, aes(x = G3)) +
geom_histogram(bins = 20, color = 'black' ,fill = 'green') +
ylab('Frequency') +
theme_minimal()
# Character variable in to numeric
labels(df[ , !is.numeric()])
# Character variable in to numeric
labels(!is.numeric(df))
str(df)
class(df$Mjob)
# Character variable transformed in numeric data
character_columns <- sapply(df, is.character)
character_columns
levels(character_columns)
summary(character_columns)
summary(df[, character_columns])
# Read the data set
df <- read.csv2('students.csv', stringsAsFactors = T)
### Exploratory data analysis
summary(df)
str(df)
any(is.na(df))
# Numeric columns
numeric_columns <- sapply(df, is.numeric)
numeric_columns
# Normalizacao
maxs <- apply(df[ ,numeric_columns], 2, max)
maxs
mins <- apply(df[ ,numeric_columns], 2, min)
mins
# Normalizando
?scale
normalized_df <- as.data.frame(scale(df[ ,numeric_columns], center = mins, scale = maxs - mins))
head(normalized_df)
summary(normalized_df)
# Correlation between numeric variable
data_cor <- cor(df[ ,numeric_columns])
data_cor
# Correlation plot
corrplot(data_cor, method = 'color')
# G3 histogram
ggplot(df, aes(x = G3)) +
geom_histogram(bins = 20, color = 'black' ,fill = 'green') +
ylab('Frequency') +
theme_minimal()
# Character variable transformed in numeric data
character_columns <- sapply(df, is.character)
summary(df[, character_columns])
# Character variable transformed in numeric data
character_columns <- sapply(df, is.factor)
summary(df[, factor_columns])
# Character variable transformed in numeric data
factor_columns <- sapply(df, is.factor)
summary(df[, factor_columns])
school <- df$school
school <- ifelse(df$school == 'GP', 0, 1)
school
normalized_df$school <- ifelse(df$school == 'GP', 0, 1)
summary(df[, factor_columns])
normalized_df$sex <- ifelse(df$sex == 'F', 0, 1)
normalized_df$address <- ifelse(df$address == 'R', 0, 1)
normalized_df$famsize <- ifelse(df$famsize == 'GT3', 0, 1)
normalized_df$Pstatus <- ifelse(df$school == 'A', 0, 1)
normalized_df$Pstatus <- ifelse(df$Pstatus == 'A', 0, 1)
normalized_df$schoolup <- ifelse(df$schoolup == 'no', 0, 1)
summary(df[, factor_columns])
normalized_df$famsup <- ifelse(df$famsup == 'no', 0, 1)
normalized_df$paid <- ifelse(df$paid == 'no', 0, 1)
normalized_df$activities <- ifelse(df$activities == 'no', 0, 1)
normalized_df$nursery <- ifelse(df$nursery == 'no', 0, 1)
normalized_df$higher <- ifelse(df$higher == 'no', 0, 1)
normalized_df$internet <- ifelse(df$internet == 'no', 0, 1)
normalized_df$romantic <- ifelse(df$romantic == 'no', 0, 1)
summary(df[, factor_columns])
summary(normalized_df)
# Character variable transformed in numeric data
factor_columns <- sapply(df, is.factor)
summary(df[, factor_columns])
normalized_df$Mjob <- ifelse(df$Mjob == 'at_home', 0,
ifelse(df$Mjob == 'health', 0.33,
ifelse(df$Mjob == 'other', 0.67, 1)))
normalized_df$Mjob
# Character variable transformed in numeric data
factor_columns <- sapply(df, is.factor)
summary(df[, factor_columns])
normalized_df$Mjob <- ifelse(df$Mjob == 'at_home', 0,
ifelse(df$Mjob == 'health', 0.25,
ifelse(df$Mjob == 'other', 0.50,
ifelse(df$Mjob == 'services', 0.75, 1))))
normalized_df$Mjob
normalized_df$Fjob <- ifelse(df$Fjob == 'at_home', 0,
ifelse(df$Fjob == 'health', 0.25,
ifelse(df$Fjob == 'other', 0.50,
ifelse(df$Fjob == 'services', 0.75, 1))))
summary(df[, factor_columns])
normalized_df$reason <- ifelse(df$reason == 'course', 0,
ifelse(df$reason == 'home', 0.33,
ifelse(df$reason == 'other', 0.67, 1)))
normalized_df$reason
summary(df[, factor_columns])
normalized_df$guardian <- ifelse(df$guardian == 'other', 0,
ifelse(df$guardian == 'fater', 0.50, 1))
normalized_df$guardian
normalized_df$guardian <- ifelse(df$guardian == 'other', 0,
ifelse(df$guardian == 'father', 0.50, 1))
normalized_df$guardian
summary(normalized_df)
str(normalized_df)
normalized_df$school
normalized_df$sex
normalized_df$address
normalized_df$famsize
normalized_df$Pstatus
normalized_df$schoolup
normalized_df$famsup
normalized_df$paid
normalized_df$activities
normalized_df$nursery
normalized_df$higher
normalized_df$higher <- ifelse(df$higher == 'no', 0, 1)
normalized_df$internet
normalized_df$internet
normalized_df$romantic
normalized_df$Mjob
normalized_df$Fjob
normalized_df$reason
normalized_df$Mjob
normalized_df$Fjob
normalized_df$reason
normalized_df$guardian
# 70% of training data set
# 30% of test data set
sp <- sample.split(df$age, SplitRatio = 0.70)
sp
# 70% of training data set
# 30% of test data set
sp <- sample.split(nrow(normalized_df), SplitRatio = 0.70)
sp
# 70% of training data set
# 30% of test data set
sp <- sample.split(normalized_df$school, SplitRatio = 0.70)
sp
train_ds <- subset(df, sp == TRUE)
head(train_ds)
dim(train_ds)
test_ds <- subset(df, sp == FALSE)
head(test_ds)
dim(test_ds)
model_8 <- lm(G3 ~ .),
data = train_ds)
model_8 <- lm(G3 ~ .,
data = train_ds)
# Summary
summary(model_8)
# Negative predicton grades
sum(predictions_8 < 0)
# Predictions
predictions_8 <- predict(model_8, test_ds)
# Negative predicton grades
sum(predictions_8 < 0)
neg <- function(x){
if  (x < 0){
return(0)
}else{
return(x)
}
}
predictions_8 <- sapply(predictions_8, neg)
# Root Mean Squared Error
(RMSE = sqrt((mean(test_ds$G3 - predictions_8)^2)))
# Residual sum of squares
(RSS = sum((test_ds$G3 - predictions_8)^2))
# Total sum of squares
(TSS = sum((test_ds$G3 - mean(df$G3))^2))
# R-Squared
(R2 = 1 - (RSS/TSS))
# Treinando o Modelo
rede_neural <- neuralnet(G3 ~ ., data = test_ds, hidden = c(6,4,2), linear.output = TRUE, rep = 2)
str(test_ds)
sapply(normalized_df, 2, as.numeric)
apply(normalized_df, 2, as.numeric)
normalized_df <- apply(normalized_df, 2, as.numeric)
summary(normalized_df)
# 70% of training data set
# 30% of test data set
sp <- sample.split(normalized_df$school, SplitRatio = 0.70)
train_ds <- subset(df, sp == TRUE)
head(train_ds)
dim(train_ds)
test_ds <- subset(df, sp == FALSE)
head(test_ds)
dim(test_ds)
# Treinando o Modelo
rede_neural <- neuralnet(G3 ~ ., data = test_ds, hidden = c(6,4,2), linear.output = TRUE, rep = 2)
str(test_ds)
str(normalized_df)
normalized_df <- sapply(normalized_df, as.numeric)
summary(normalized_df)
str(normalized_df)
# Removes all existing objects and packages from the current workspace
rm(list = ls())
lapply(paste("package:", names(sessionInfo()$otherPkgs), sep=""), detach, character.only = TRUE, unload = TRUE)
# Working directory
setwd("~/Documents/learning_Data_Science/R_scripts")
getwd()
# Problem: Predict student final grades (G3)
# Data set site: https://archive.ics.uci.edu/ml/datasets/Student+Performance
# Method: Neural Network with a linear model
# Definindo o Problema: Analisando dados das casas de Boston, nos EUA e fazendo previsoes.
# The Boston Housing Dataset
# http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html
# Seu modelo deve prever a MEDV (Valor da Mediana de ocupação das casas).
# Packages
library(corrplot)
library(ggplot2)
library(neuralnet)
library(caTools)
# Read the data set
df <- read.csv2('students.csv', stringsAsFactors = F)
# View(df)
### Exploratory data analysis
summary(df)
str(df)
any(is.na(df))
# Numeric columns
numeric_columns <- sapply(df, is.numeric)
numeric_columns
# Normalizacao
maxs <- apply(df[ ,numeric_columns], 2, max)
maxs
mins <- apply(df[ ,numeric_columns], 2, min)
mins
# Normalizando
?scale
normalized_df <- as.data.frame(scale(df[ ,numeric_columns], center = mins, scale = maxs - mins))
head(normalized_df)
summary(normalized_df)
# Correlation between numeric variable
data_cor <- cor(df[ ,numeric_columns])
data_cor
# Correlation plot
corrplot(data_cor, method = 'color')
# This plot shows that there are three major positive correlation spots near the
# main diagonal: the first is between Medu and Fedu, the second has freetime,
# goout, Dalc, and Walc, and the third is the strongest and it has G1, G2, and G3.
# G3 histogram
ggplot(df, aes(x = G3)) +
geom_histogram(bins = 20, color = 'black' ,fill = 'green') +
ylab('Frequency') +
theme_minimal()
# Character variable transformed in numeric data
factor_columns <- sapply(df, is.factor)
summary(df[, factor_columns])
normalized_df$school <- ifelse(df$school == 'GP', 0, 1)
normalized_df$sex <- ifelse(df$sex == 'F', 0, 1)
normalized_df$address <- ifelse(df$address == 'R', 0, 1)
normalized_df$famsize <- ifelse(df$famsize == 'GT3', 0, 1)
normalized_df$Pstatus <- ifelse(df$Pstatus == 'A', 0, 1)
normalized_df$schoolup <- ifelse(df$schoolup == 'no', 0, 1)
normalized_df$famsup <- ifelse(df$famsup == 'no', 0, 1)
normalized_df$paid <- ifelse(df$paid == 'no', 0, 1)
normalized_df$activities <- ifelse(df$activities == 'no', 0, 1)
normalized_df$nursery <- ifelse(df$nursery == 'no', 0, 1)
normalized_df$higher <- ifelse(df$higher == 'no', 0, 1)
normalized_df$internet <- ifelse(df$internet == 'no', 0, 1)
normalized_df$romantic <- ifelse(df$romantic == 'no', 0, 1)
normalized_df$Mjob <- ifelse(df$Mjob == 'at_home', 0,
ifelse(df$Mjob == 'health', 0.25,
ifelse(df$Mjob == 'other', 0.50,
ifelse(df$Mjob == 'services', 0.75, 1))))
normalized_df$Fjob <- ifelse(df$Fjob == 'at_home', 0,
ifelse(df$Fjob == 'health', 0.25,
ifelse(df$Fjob == 'other', 0.50,
ifelse(df$Fjob == 'services', 0.75, 1))))
normalized_df$reason <- ifelse(df$reason == 'course', 0,
ifelse(df$reason == 'home', 0.33,
ifelse(df$reason == 'other', 0.67, 1)))
normalized_df$guardian <- ifelse(df$guardian == 'other', 0,
ifelse(df$guardian == 'father', 0.50, 1))
str(normalized_df)
summary(normalized_df)
# 70% of training data set
# 30% of test data set
sp <- sample.split(normalized_df$school, SplitRatio = 0.70)
train_ds <- subset(df, sp == TRUE)
head(train_ds)
dim(train_ds)
test_ds <- subset(df, sp == FALSE)
head(test_ds)
dim(test_ds)
str(test_ds)
# 70% of training data set
# 30% of test data set
sp <- sample.split(normalized_df$school, SplitRatio = 0.70)
train_ds <- subset(normalized_df, sp == TRUE)
head(train_ds)
dim(train_ds)
test_ds <- subset(normalized_df, sp == FALSE)
head(test_ds)
dim(test_ds)
# Treinando o Modelo
rede_neural <- neuralnet(G3 ~ ., data = test_ds, hidden = c(6,4,2), linear.output = TRUE, rep = 2)
# Summary
summary(rede_neural)
# Fazendo previsoes com os dados de teste
a <- predict(rede_neural, teste)
# Convertendo os dados de teste
previsoes <- a * (max(dados$medv) - min(dados$medv)) + min(dados$medv)
# Fazendo previsoes com os dados de teste
a <- predict(rede_neural, test_ds)
# Convertendo os dados de teste
previsoes <- a * (max(dados$medv) - min(dados$medv)) + min(dados$medv)
# Convertendo os dados de teste
previsoes <- a * (max(dados$medv) - min(dados$medv)) + min(dados$medv)
# Convertendo os dados de teste
previsoes <- a * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
teste_convert <- (test_d$G3) * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
teste_convert <- (test_ds$G3) * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
teste_convert
(RMSE = sqrt((mean(teste_convert - previsoes)^2)))
# Residual sum of squares
(RSS = sum((teste_convert - previsoes)^2))
# Total sum of squares
(TSS = sum((teste_convert - mean(previsoes))^2))
# R-Squared
(R2 = 1 - (RSS/TSS))
# Plot dos erros
ggplot(error.df, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
# Plot dos erros
ggplot(previsoes, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
head(error.df)
# Plot dos erros
ggplot(previsoes, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
head(error.df)
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes)
head(error.df)
# Plot dos erros
ggplot(previsoes, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
# Plot dos erros
ggplot(error.df, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
# Negative predicton grades
sum(previsoes < 0)
neg <- function(x){
if  (x < 0){
return(0)
}else{
return(x)
}
}
predictions_8 <- sapply(predictions_8, neg)
predictions_8 <- sapply(previsoes, neg)
previsoes <- sapply(previsoes, neg)
# Root Mean Squared Error
(RMSE = sqrt((mean(teste_convert - previsoes)^2)))
# Residual sum of squares
(RSS = sum((teste_convert - previsoes)^2))
# Total sum of squares
(TSS = sum((teste_convert - mean(previsoes))^2))
# R-Squared
(R2 = 1 - (RSS/TSS))
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes)
head(error.df)
# Plot dos erros
ggplot(error.df, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
# Treinando o Modelo
rede_neural <- neuralnet(G3 ~ ., data = test_ds, hidden = c(6,4,2), linear.output = TRUE)
# Fazendo previsoes com os dados de teste
a <- predict(rede_neural, test_ds)
# Convertendo os dados de teste
previsoes <- a * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
teste_convert <- (test_ds$G3) * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
# Negative predicton grades
sum(previsoes < 0)
neg <- function(x){
if  (x < 0){
return(0)
}else{
return(x)
}
}
previsoes <- sapply(previsoes, neg)
# Root Mean Squared Error
(RMSE = sqrt((mean(teste_convert - previsoes)^2)))
# Residual sum of squares
(RSS = sum((teste_convert - previsoes)^2))
# Total sum of squares
(TSS = sum((teste_convert - mean(previsoes))^2))
# R-Squared
(R2 = 1 - (RSS/TSS))
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes)
head(error.df)
# Plot dos erros
ggplot(error.df, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
head(error.df)
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, round(previsoes, 2))
head(error.df)
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes = round(previsoes, 2))
head(error.df)
# Convertendo os dados de teste
previsoes <- a * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
teste_convert <- (test_ds$G3) * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
teste_convert
# Negative predicton grades
sum(previsoes < 0)
neg <- function(x){
if  (x < 0){
return(0)
}else{
return(x)
}
}
previsoes <- sapply(previsoes, neg)
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes = round(previsoes, 2))
head(error.df)
teste_convert
teste_convert <- (test_ds$G3) * (max(normalized_df$G3) - min(normalized_df$G3)) + min(normalized_df$G3)
teste_convert
# Convertendo os dados de teste
previsoes <- a * (max(df$G3) - min(df$G3)) + min(df$G3)
teste_convert <- (test_ds$G3) * (max(df$G3) - min(df$G3)) + min(df$G3)
teste_convert
# Negative predicton grades
sum(previsoes < 0)
neg <- function(x){
if  (x < 0){
return(0)
}else{
return(x)
}
}
previsoes <- sapply(previsoes, neg)
# Root Mean Squared Error
(RMSE = sqrt((mean(teste_convert - previsoes)^2)))
# Residual sum of squares
(RSS = sum((teste_convert - previsoes)^2))
# Total sum of squares
(TSS = sum((teste_convert - mean(previsoes))^2))
# R-Squared
(R2 = 1 - (RSS/TSS))
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes = round(previsoes, 2))
head(error.df)
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes = round(previsoes))
head(error.df)
# Plot dos erros
ggplot(error.df, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
sum(teste_convert == round(previsoes))
sum(teste_convert == round(previsoes))/length(teste_convert)
# Treinando o Modelo
rede_neural <- neuralnet(G3 ~ ., data = test_ds, hidden = c(20, 10, 5, 2), linear.output = TRUE)
# Fazendo previsoes com os dados de teste
a <- predict(rede_neural, test_ds)
# Convertendo os dados de teste
previsoes <- a * (max(df$G3) - min(df$G3)) + min(df$G3)
teste_convert <- (test_ds$G3) * (max(df$G3) - min(df$G3)) + min(df$G3)
# Negative predicton grades
sum(previsoes < 0)
neg <- function(x){
if  (x < 0){
return(0)
}else{
return(x)
}
}
previsoes <- sapply(previsoes, neg)
# Root Mean Squared Error
(RMSE = sqrt((mean(teste_convert - previsoes)^2)))
# Residual sum of squares
(RSS = sum((teste_convert - previsoes)^2))
# Total sum of squares
(TSS = sum((teste_convert - mean(previsoes))^2))
# R-Squared
(R2 = 1 - (RSS/TSS))
# Proporçaõ de notas iguais
sum(teste_convert == round(previsoes))/length(teste_convert)
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes = round(previsoes))
head(error.df)
# Plot dos erros
ggplot(error.df, aes(x = teste_convert,y = previsoes)) +
geom_point() + stat_smooth()
# Read the data set
df <- read.csv2('students.csv', stringsAsFactors = F)
View(df)
