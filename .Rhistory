install.packages("caret")
# Instalar pacotes
install.packages('randonForest')
# Instalar pacotes
install.packages('randonForest')
install.packages('ggplot2')
# Instalar pacotes
install.packages('randomForest')
# Instalar pacotes
install.packages('randomForest')
# Instalar pacotes
install.packages('randomForest')
# Instalar pacotes
install.packages('randomForest')
# Instalar pacotes
#install.packages('randomForest')
# Instalar pacotes
#install.packages('randomForest')
install.packages('ggplot2')
install.packages('dplyr')
install.packages('devtools')
# Carregar o pacote
library(ggplot2)
# Descarregar o pacote
detach(package:ggplot2)
# Descarregar o pacote
detach(package:ggplot2)
# Carregar o pacote
library(ggplot2)
# Descarregar o pacote
detach(ggplot2)
package:
# Descarregar o pacote
detach(package:ggplot2)
# Se souber o nome da função
help(mean)
?mean
?mean
# Para buscar mais opções sobre uma função, use o pacote SOS
install.packege('sos')
# Para buscar mais opções sobre uma função, use o pacote SOS
install.package('sos')
# Para buscar mais opções sobre uma função, use o pacote SOS
install.packages('sos')
library(sos)
# Para buscar mais opções sobre uma função, use o pacote SOS
install.packages('sos')
install.packages("sos")
findFn('fread')
# Para buscar mais opções sobre uma função, use o pacote SOS
install.packages('sos')
library(sos)
findFn('fread')
# Se não souber o nome da função
help.search('randomForest')
help.search('matplot')
??matplot
RSiteSarch('matplot')
RSiteSearch('matplot')
examplo('matplot')
example('matplot')
# Sair
q()
# Sair
q()
?dplyr
??dplyr
??dplyr::sql
exit
eit
exit
q
q()
q()
q()
sample(c(1:25), 15, replace = F)
sort(sample(c(1:25), 15, replace = F))
sort(sample(c(1:25), 15, replace = F))
sort(sample(c(1:25), 15, replace = F))
x <- c(1,2,3)
y <- c(2,3,4)
model <- lm(y ~ x)
model
y <- c(2,5,7)
model <- lm(y ~ x)
model
# Removes all existing objects from the current workspace
rm(list = ls())
# Working directory
setwd("~/Documents/learning_Data_Science/R_scripts")
getwd()
# Problem: Predict student final grades (G3)
# Data set site: https://archive.ics.uci.edu/ml/datasets/Student+Performance
# Method: k-Nearest Neighbour Classification
# Packages
library(class)
library(dplyr)
library(gmodels)
library(caret)
?knn
# Read data set
df <- read.csv2('students.csv', stringsAsFactors = F)
### The exploratory data analysis was done in PART 1 with the Linear Model
# Verifying if NA data exist
sum(is.na(df))
### Division into training and test data
# Relative proportion of schools
round(prop.table(table(df$school)), 2)
# Sort by school
df <- df %>%
arrange(school)
View(df)
# ID column insertion
df$ID <- c(1:dim(df)[1])
# School IDs
GP_school <- df$ID[df$school == 'GP']
MS_school <- df$ID[df$school == 'MS']
# 70% of training observations
# 30% of test observations
# GP school
GP_school_test <- sample(GP_school, round(length(GP_school)*0.30))
GP_school_test <- df[df$ID %in% GP_school_test, ]
GP_school_test
GP_school_train <- GP_school[!(GP_school) %in% GP_school_test$ID]
GP_school_train <- df[df$ID %in% GP_school_train, ]
GP_school_train
# Checking if the number of rows of training and test data are equal to the total
(nrow(GP_school_test) + nrow(GP_school_train)) == length(GP_school)
# MS school
MS_school_test <- sample(MS_school, round(length(MS_school)*0.30))
MS_school_test <- df[df$ID %in% MS_school_test, ]
MS_school_test
MS_school_train <- MS_school[!(MS_school) %in% MS_school_test$ID]
MS_school_train <- df[df$ID %in% MS_school_train, ]
MS_school_train
# Checking if the number of rows of training and test data are equal to the total
(nrow(MS_school_test) + nrow(MS_school_train)) == length(MS_school)
# Concatenating the training data sets of the schools
data_train <- rbind(GP_school_train, MS_school_train)
data_train <- data_train[ , colnames(df) != 'ID']
dim(data_train)
# Concatenating the test data sets of the schools
data_test <- rbind(GP_school_test, MS_school_test)
data_test <- data_test[ , colnames(df) != 'ID']
dim(data_test)
### Making classes of grades, as in the reference of the data set site entitled
### "Cortes, P., Silva, A. USING DATA MINING TO PREDICT SECONDARY SCHOOL STUDENT
###  PERFORMANC. University of Minho. Portugal"
grade_classes <- function(x) {
if (x > 15) {x = "A"}
else if (x < 10) {x = "F"}
else if (x == 14 | x == 15) {x = "B"}
else if (x == 12 | x == 13) {x = "C"}
else {x = "D"}
}
data_train$G3 <- sapply(data_train$G3, grade_classes)
data_train$G3 <- as.factor(data_train$G3)
str(data_train$G3)
View(data_train)
data_test$G3 <- sapply(data_test$G3, grade_classes)
data_test$G3 <- as.factor(data_test$G3)
str(data_test$G3)
View(data_test)
data_train_labels <- as.factor(data_train$G3)
data_train_labels
data_test_labels <- as.factor(data_test$G3)
data_test_labels
# The KNN algorithm does not except string or factor type
# Selecting the numeric columns
str(data_train)
data_train_num <- select_if(data_train, is.numeric)
head(data_train_num)
data_test_num <- select_if(data_test, is.numeric)
head(data_test_num)
################################################################################
################################################################################
################################################################################
# Model 1 - KNN model, where the target variable depends on all the numeric
#           variables
# Model 1 - KNN model, where the target variable depends on all the numeric
#           variables
model_1 <- knn(train = data_train_num,
test = data_test_num,
cl = data_train_labels,
k = 3)
# Confusion Matrix
confusionMatrix(data_test$G3, model_1)
# Model 1 - KNN model, where the target variable depends on all the numeric
#           variables
model_1 <- knn(train = data_train_num,
test = data_test_num,
cl = data_train_labels,
k = 100)
# Confusion Matrix
confusionMatrix(data_test$G3, model_1)
