knitr::opts_chunk$set(echo = TRUE)
# Number of rows in the train dataset
# The train dataset named train.csv can be found on the web site
# https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data
n_rows <- fread(file = 'train.csv', header = T, select = 'is_attributed')
setwd("~/Documents/learning_Data_Science/R_learnings/Project_1_in_R")
# getwd()
# Packages
library(dplyr)
library(data.table)
library(caret)
library(randomForest)
library(DMwR)
library(knitr)
library(rmarkdown)
n_rows <- fread(file = 'train.csv', header = T, select = 'is_attributed')
n_rows <- nrow(n_rows)
n_rows    # 184.903.890 rows
gc()
# Calculating the number of batches
for (i in c(15:100)) {
if (n_rows%%i == 0) {
print(c(i, n_rows/i))
}
}             # 15 seems better for my computer capacity
rm(i)
# Batches
#n = 15
train_set <- data.frame(is_attributed = c(),
app = c(),
channel = c(),
repetitions_fac = c(),
app_fac = c())
#for (i in c(0:(n-1))) {
i=0
if (i == 0) {
# The train dataset named train.csv can be found on the web site
# https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data
train <- fread(file = 'train.csv', header = T,
#                 skip = n_rows/n*i, nrows = n_rows/n,
nrows = 1e6,
select = c('is_attributed', 'ip', 'app', 'channel'))
} else {
train <- fread(file = 'train.csv', header = F,
skip = n_rows/n*i, nrows = n_rows/n,
select = c(8,1,2,5))
names(train) <- c('is_attributed', 'ip', 'app', 'channel')
}
# ip feature
# Repeated ips in order
n_dupl_ips <- train %>%
count(ip, wt = n(), name = 'repetitions') %>%
arrange(desc(repetitions))
# Number of duplicate ips column
train <- left_join(train, n_dupl_ips, by = 'ip')
train$ip <- NULL
# repetitions classes
train$repetitions_fac <- cut(train$repetitions,
breaks = c(0,5,nrow(train)),
labels = c(1, 2))
train$repetitions <- NULL
# app classes
train$app_fac <- cut(train$app,
breaks = c(0, 3, 12, 18, nrow(train)),
right = F, labels = c(1, 2, 3, 4))
# is_attributed classes
train <- train %>%
mutate(is_attributed = factor(is_attributed, levels = c(1,0)))
head(train_set)
# Balancing the target class
train <- SMOTE(is_attributed ~ ., data  = train)
# Binding the train dataset
train_set <- rbind(train_set, train)
rm(n_dupl_ips, train)
gc()
print(i)
}
#for (i in c(0:(n-1))) {
i=0
if (i == 0) {
# The train dataset named train.csv can be found on the web site
# https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data
train <- fread(file = 'train.csv', header = T,
#                 skip = n_rows/n*i, nrows = n_rows/n,
nrows = 1e6,
select = c('is_attributed', 'ip', 'app', 'channel'))
} else {
train <- fread(file = 'train.csv', header = F,
skip = n_rows/n*i, nrows = n_rows/n,
select = c(8,1,2,5))
names(train) <- c('is_attributed', 'ip', 'app', 'channel')
#}
# ip feature
# Repeated ips in order
n_dupl_ips <- train %>%
count(ip, wt = n(), name = 'repetitions') %>%
arrange(desc(repetitions))
# Number of duplicate ips column
train <- left_join(train, n_dupl_ips, by = 'ip')
train$ip <- NULL
# repetitions classes
train$repetitions_fac <- cut(train$repetitions,
breaks = c(0,5,nrow(train)),
labels = c(1, 2))
train$repetitions <- NULL
# app classes
train$app_fac <- cut(train$app,
breaks = c(0, 3, 12, 18, nrow(train)),
right = F, labels = c(1, 2, 3, 4))
# is_attributed classes
train <- train %>%
mutate(is_attributed = factor(is_attributed, levels = c(1,0)))
head(train_set)
# Balancing the target class
train <- SMOTE(is_attributed ~ ., data  = train)
# Binding the train dataset
train_set <- rbind(train_set, train)
rm(n_dupl_ips, train)
gc()
print(i)
}
# training data set dimension
dim(train_set)
# Number of downloads, indicated by "1"
table(train_set$is_attributed)
# Features types
str(train_set)
head(train_set)
# Random forest model
model15 <- randomForest(is_attributed ~ repetitions_fac * app +
channel * app_fac,
data = train_set,
ntree = 10,
nodesize = 1)
``` {r training_the_model}
# Random forest model
model15 <- randomForest(is_attributed ~ repetitions_fac * app +
channel * app_fac,
data = train_set,
ntree = 10,
nodesize = 1)
# Features types
str(train_set)
``` {r reading_and_tidyng_the_training_dataset}
knitr::opts_chunk$set(echo = TRUE)
# Removes all existing objects and packages from the current workspace
rm(list = ls())
# Working directory
setwd("~/Documents/learning_Data_Science/R_learnings/Project_1_in_R")
# getwd()
# Packages
library(dplyr)
library(data.table)
library(caret)
library(randomForest)
library(DMwR)
library(knitr)
library(rmarkdown)
``` {r reading_and_tidyng_the_training_dataset}
